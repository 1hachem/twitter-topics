{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "imports"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from src.utils import load_pickle, save_pickle, split_data\n",
    "from src.model import get_embedding, DivideAndConquerFNN, GPT_3, classifiers_predict\n",
    "from src.train import train_fnns, classifiers_fit\n",
    "from src.evaluation import evaluate\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATHS\n",
    "RAW_DATA_PATH = '../data/raw/text_topics.pkl'\n",
    "PROCESSED_DATA_PATH = '../data/processed/embedded.pkl'\n",
    "FINETUNING_JSON_PATH = '../data/processed/data.json'\n",
    "FINETUNED_MODEL_NAME = 'ada:ft-personal-2023-03-11-12-31-10'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA & Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpickle the data\n",
    "raw_data = load_pickle(RAW_DATA_PATH)\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the date and id columns\n",
    "# I dont think date and id are relevant to classify the topic, it will only bias the model\n",
    "# during inference date and id are going to be outside the distribution of the training data  \n",
    "df = raw_data.drop(columns=[\"date\", \"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate all topics lists into one list\n",
    "topics = [topic for topics in df.topics for topic in topics]\n",
    "# get unique topics\n",
    "unique_topics = np.unique(topics)\n",
    "print(unique_topics, f\"there are {len(unique_topics)} unique topics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of samples for each topic and plot it \n",
    "topic_count = [len(df[df.topics.apply(lambda x: topic in x)]) for topic in unique_topics]\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x=unique_topics, y=topic_count)\n",
    "plt.xlabel(\"Topic\")\n",
    "plt.ylabel(\"Number of samples\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Number of samples per topic\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode the topics column and store it in a list \n",
    "# this will be used to create the target column\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(unique_topics)\n",
    "df[\"target\"] = df.topics.apply(lambda x: lb.transform(x).sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_topics.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the distribution of the number of topics per sample ?\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(x=df.topics.apply(lambda x: len(x)))\n",
    "plt.xlabel(\"Number of topics\")\n",
    "plt.ylabel(\"Number of samples\")\n",
    "plt.title(\"Distribution of the number of topics per sample\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of the number of topics in a sample per topic\n",
    "# sns subplots\n",
    "fig, axs = plt.subplots(5, 4, figsize=(20, 15))\n",
    "for topic, ax in zip(unique_topics, axs.flatten()):\n",
    "    ax.set(xlabel=f\"{topic}\", ylabel='samples count')\n",
    "    sns.histplot(x=df[df.topics.apply(lambda x: topic in x)].topics.apply(lambda x: len(x)), ax=ax)\n",
    "axs.flatten()[-1].remove()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data cleaning \n",
    "# remove username and url from the text\n",
    "# remove emojis "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one idea would be to use pre-trained LLMs to embed each tweet, we would than use these embeddings to train a classifier (a feed-forward neural network, SVM). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##########################################################\n",
    "# ## uncomment this if you want to get your own embeddings##\n",
    "# ##########################################################\n",
    "\n",
    "# # get the embedding for each sample\n",
    "# embeddings = []\n",
    "# for text in df.text:\n",
    "#     try:\n",
    "#         embeddings.append(get_embedding(text))\n",
    "#     except:\n",
    "#         print(\"error !\", \"total embedded samples:\", len(embeddings))\n",
    "#         # save the embeddings so far\n",
    "#         with open(f'../data/processed/{len(embeddings)}_embeddings.pkl', 'wb') as f:\n",
    "#             pickle.dump(embeddings, f)\n",
    "#         break\n",
    "\n",
    "# # check that the number of embeddings is equal to the number of samples\n",
    "# assert len(embeddings) == len(df)\n",
    "# # add the embeddings to the dataframe\n",
    "# df[\"embedding\"] = embeddings\n",
    "# # save the processed data\n",
    "# save_pickle(df, PROCESSED_DATA_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the processed data\n",
    "df_processed = load_pickle(PROCESSED_DATA_PATH)\n",
    "x, y = df_processed.embedding.to_list(), df_processed.target.to_list()\n",
    "x, y = np.array(x, dtype=np.float32), np.array(y, dtype=np.float32)\n",
    "# split the data into train, validation and test sets\n",
    "x_train, x_val, x_test, y_train, y_val, y_test = split_data(x, y, test_size=0.2, val_size=0.1)\n",
    "x_train, x_val, x_test, y_train, y_val, y_test = torch.tensor(x_train), torch.tensor(x_val), torch.tensor(x_test), torch.tensor(y_train), torch.tensor(y_val), torch.tensor(y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "task : mutli-label classification (one vs. rest Classification)\n",
    "\n",
    "experiment : feedforward neural network on top of ada-002 embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model and hyperparameters\n",
    "input_dim = len(x_train[0])\n",
    "hidden_dim = 16\n",
    "number_of_labels = len(unique_topics)\n",
    "\n",
    "classifier = DivideAndConquerFNN(input_dim, hidden_dim, number_of_labels)\n",
    "\n",
    "batch_size = 16\n",
    "num_epochs = 10\n",
    "\n",
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = TensorDataset(x_val, y_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "learning_rate = 3e-4\n",
    "optimizer = torch.optim.Adam(classifier.parameters(), lr=learning_rate)\n",
    "criterions = [torch.nn.BCELoss() for _ in range(number_of_labels)]\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the classifier\n",
    "train_fnns(classifier, train_loader, val_loader, optimizer, criterions, num_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference and evaluation\n",
    "y_pred = [[pred.item() for pred in res] for res in classifier(x_train)]\n",
    "y_pred = (np.array(y_pred)>=0.5).astype(int).T\n",
    "y_truth = np.array(y_train).astype(int)\n",
    "\n",
    "evaluate(y_truth, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task : few-shot learning\n",
    "\n",
    "Experiment : GPT-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# few-shot prompt  \n",
    "prompt = lambda text : f\"\"\"\n",
    "classify tweets to their topics, available topics are: {str(unique_topics)}\n",
    "tweet : Barbara Bailey is the queen of broadcast news in central & eastern Kentucky  After growing up watching her anchor the news, it was a great honor to call her coworker & friend. I loved saying “back to you, Barb” while reporting.  Cheers, {{USERNAME}} {{URL}} \n",
    "output : ['film_tv_&_video','news_&_social_concern']\n",
    "tweet : Saints defense was dinged for 4 missed tackles in Week 1, tying the Texans and Colts for the 6th fewest in the NFL  Saints defense credited with 8 pressures (3 sacks), a pressure rate of 20%. Ties Rams for 14th worst in Week 1  per ProFootballReference\n",
    "output : ['sports']\n",
    "tweet : Earning gift cards for selling my stuff on @Listia@ ! Join me using code  BBDBPG  for an extra 250 PTS. I just listed this: LARGE KANSAS CITY LOGO MAGNET (PLEASE READ DESCRIPTION) URL\n",
    "output : ['business_&_entrepreneurs']\n",
    "tweet : {text}\n",
    "output : [\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_test_set = df.sample(10)\n",
    "gpt_test_set_x = gpt_test_set.text.to_list()\n",
    "gpt_test_set_y = gpt_test_set.target.apply(list).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference\n",
    "responses = []\n",
    "for x in gpt_test_set_x:\n",
    "    prediction = GPT_3(prompt(x))\n",
    "    prediction = eval(\"[\" + prediction + \"]\")\n",
    "    responses.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode the responses\n",
    "gpt_pred_y = [list(lb.transform(respone).sum(axis=0)) for respone in responses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "evaluate(gpt_test_set_y, gpt_pred_y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Higher quality examples should be prepared for few-shot prompts, we could use chain-of-thoughts prompting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task : text generation\n",
    "\n",
    "Experiment : fine-tuning GPT-3 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "report on : https://api.wandb.ai/links/dsia/xxv7s8nz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data for finetuning later on\n",
    "df_ = pd.DataFrame()\n",
    "df_[\"prompt\"] = df.text\n",
    "df_[\"completion\"] = df.topics.apply(str)\n",
    "df_.to_json(FINETUNING_JSON_PATH, orient=\"records\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check README for steps on how to fine-tune gpt-3 with openai API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference\n",
    "# responses = []\n",
    "# for x in gpt_test_set_x:\n",
    "#     prediction = GPT_3(x + \"-> [\", model=FINETUNED_MODEL_NAME)\n",
    "#     prediction = eval(\"[\" + prediction + \"]\")\n",
    "#     responses.append(prediction)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:#990000\"> fine tuned model is not respecting the syntax :p </p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task : one vs rest classification\n",
    "\n",
    "Experiment : different sklearn classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [DecisionTreeClassifier(max_depth=3) for _ in unique_topics]\n",
    "classifiers_fit(classifiers, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifiers_predict(classifiers, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twitter-topic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
